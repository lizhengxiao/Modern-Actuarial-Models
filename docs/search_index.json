[["index.html", "现代精算统计模型 👨‍🏫 欢迎 🤔 答疑 🗓️ 课程安排", " 现代精算统计模型 Modern Actuarial Models 2021-01-10 16:52:16 👨‍🏫 欢迎 《现代精算统计模型》主要讲述如何使用统计学习和机器学习算法，提升传统的精算统计模型或者解决新的精算问题。这门课主要参考瑞士精算师协会发布的“精算数据科学”，该教程的主要目的是“为精算师提供一个对数据科学全面且易懂的介绍”，该教程提供了多篇方法性文章并开源代码，这样“读者可以相对容易地把这些数据科学方法用在自己的数据上”。 我们建议大家仔细阅读以下文献，尝试并理解所有代码。此网站将作为该课程的辅助，为大家答疑，总结文献，并对文献中的方法做扩展。该网站由授课老师高光远和助教张玮钰管理，欢迎大家反馈意见到助教、微信群、或邮箱 guangyuan.gao@ruc.edu.cn。 🤔 答疑 我定期把同学们的普遍疑问在这里解答，欢迎提问！ 👉 Tensorflow for Apple M1 (2020/12/23) 购买Apple M1的同学需要用这个pre-release tensorflow，从pypi下载的tensorflow暂不支持Apple M1 👉 NLP (2020/12/18) 数据 这个数据第\\(i\\)行\\(j\\)列表示，在第\\(i\\)个评论中第\\(j\\)个词的排名(依照总出现频率)，所以每一行还保持了句子中词语的先后顺序。每一行都是一个时间序列数据（样本）。 LSTM input维度是batch size * length * 1，即以上所示的.csv矩阵文档。 embedding_3 作用就是把input的最后一个维度爆炸到256，参数个数为vocab_size* embedding dimension，可以看作把400个高频词映射到256维空间。 embedding_3和lstm_2输出维度中，有两个none,其中第一个表示batch size, 第二个表示sequence length。因为LSTM在时间维度上循环使用参数，所以sequence length不影响参数的个数。 sequence length不影响参数个数，对于不同的句子长度如100或者150，该模型都不需要调整，(应该)可以直接载入数据训练。 lstm_3 只有一个none, 表示batch size, 我们要求lstm_3不返回整个sequence只看最近的状态。 👉 Reproducible results using Keras (2020/12/11) 使用Keras复现结果的方法。 https://cran.r-project.org/web/packages/keras/vignettes/faq.html 👉 为什么不直接用relu解决vanishing gradient 而设计复杂的lstm gru (2020/12/11) relu值域在0到无穷，不如tanh和sigmoid稳健，后两种可以认为把极大极小值都截断了。 relu是线性变换，可能描述不了非线性效应。我最常用tanh。 当然，使用relu会明显提升计算速度，因为relu的导数容易计算。 另参见stackexchange 👉 xaringan (2020/12/06) html格式的slides： https://slides.yihui.org/xaringan/zh-CN.html#1 👉 samme.r (2020/11/27) 关于samme.r算法, 请参考下面文章中的exponential loss function. https://web.stanford.edu/~hastie/Papers/samme.pdf 算法samme.r仅在以上draft中出现，正式发表时samme.r被删掉了，推测审稿人有异议。正式文章参考 http://ww.web.stanford.edu/~hastie/Papers/SII-2-3-A8-Zhu.pdf 👉 随机种子数 (2020/11/20) 输入RNGversion(\"3.5.0\"); set.seed(100)，使得你的随机种子数和paper的相同，模型结果相近。 👉 MAC OS, Linux, WIN (2020/11/16) 据观察，在MAC OS和Linux系统下安装keras成功的比例较高。WIN系统下，Python各个包的依赖以及和R包的匹配有一定的问题，今天是通过更换镜像源解决了R中无法加载tensorflow.keras模块的问题，推测是TUNA源中WIN包依赖关系没有及时更新。 为了解决镜像源更新延迟、或者tensorflow版本过低的问题，这里共享WIN下经测试的conda环境配置。下载该文档，从该文档所在文件夹启动命令行，使用命令conda env create --name &lt;env&gt; --file filename.yaml，安装该conda环境。在R中使用reticulate::use_condaenv(\"&lt;env&gt;\",required=T)关联该环境。 另外，可下载MAC OS系统下经测试的conda环境配置。可通过conda env create --name &lt;env&gt; --file filename.yaml安装。 👉 CASdatasets (2020/11/13) 源文件在http://cas.uqam.ca/，但下载速度很慢，我把它放在坚果云共享。下载后选择install from local archive file。 👉 微信群 (2020/11/08) 🗓️ 课程安排 以下安排为初步计划，根据大家的需求和背景，我们可能要花更多的时间在某些重要的方法及其在精算上的应用。 第10周： 准备工作。 第11周: 1 - French Motor Third-Party Liability Claims https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3164764 机动 2 - Inisghts from Inside Neural Networks https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3226852 3 - Nesting Classical Actuarial Models into Neural Networks https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3320525 第12周： 4 - On Boosting: Theory and Applications https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3402687 第13周： 5 - Unsupervised Learning: What is a Sports Car https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3439358 第14周： 6 - Lee and Carter go Machine Learning: Recurrent Neural Networks https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3441030 第15周： 7 - The Art of Natural Language Processing: Classical, Modern and Contemporary Approaches to Text Document Classification https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3547887 第16周： 8 - Peeking into the Black Box: An Actuarial Case Study for Interpretable Machine Learning https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3595944 第17周： 9 - Convolutional neural network case studies: (1) Anomalies in Mortality Rates (2) Image Recognition https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3656210 "],["cnn.html", "1 卷积神经网络 1.1 基本组件 1.2 特性 1.3 案例分析", " 1 卷积神经网络 万淇、蔡清扬、高光远 深度学习之所以这么热，大部分归功于卷积神经网络在计算机视觉上取得的巨大成功。卷积神经网络还可以用在自然语言处理、时间序列分析、异常检测、可穿戴设备与健康检测、GO。 大型预先训练的CNNs库可用于图像识别：AlexNet，GoogLeNet，ResNet, Inception, MobileNet,，VGG， DenseNet,，NASNet 等。它们可以直接使用，将某一图像分类至已知的类别之中 也可以应用于迁移学习。 Figure 1.1: Transfer learning 1.1 基本组件 1.1.1 卷积层 (Convolution) 1.1.2 池化层 (Pooling) 1.1.3 全连接层 (Dense) 1.1.4 批标准化层 (Batch Normalization) 1.1.5 扁平化 (Flatten) 1.1.6 输出神经元 1.1.7 激活函数 (Activation) 1.2 特性 1.2.1 平移不变性 (Shift Invariant) 1.2.2 旋转 1.2.3 尺度 1.3 案例分析 1.3.1 Human Mortality Database (HMD) 目标: 根据死亡率表的局部特征(\\(10\\times10\\))，检测该局部异常死亡率强度。 死亡率\\(q_{x,t,c,g}\\)、人口数量\\(E_{x,t,c,g}\\) 年龄\\(x\\), 日历年\\(t\\), 国家\\(c\\), 性别\\(g\\). 由于领土的变化，某些年的数据会出现变更前与变更后的的两个数据，处理方式是取平均值作为最后的研究数据。 某些死亡率数据存在缺失：如果相邻(以年龄\\(x\\)和日历年\\(t\\))值可用，我们线性插补，否则使用最近邻的值进行插补。 假定没有人口的迁移以及其他的误差：\\[E_{x,t,c,g}=E_{x-1,t-1,c,g}(1-q_{{x-1},{t-1},c,g})\\] 定义标准化残差: \\[r_{x,t,c,g}=\\frac{E_{x,t,c,g}-E_{x-1,t-1,c,g}(1-q_{x-1,t-1,c,g})}{E_{x,t,c,g}}\\] \\(r_{x,t,c,g}&lt;0\\)表明可能有人口迁出或者数据错误， \\(r_{x,t,c,g}&gt;0\\)表明可能有人口迁入或者数据错误。 经过预处理HMD，对每个国家每个性别我们得到一个关于死亡率\\(q_{x,t,c,g}\\)的二维数组，其中行代表不同日历年，列代表不同年龄。为了检测死亡率的异常值，我们考虑死亡率的局部变化特征，使用大小为\\(10\\times10\\)的窗口在死亡率二维数组上进行移动，并设置步长为\\(5\\)。可以得到死亡率的局部矩阵\\((q_{x,t,c,g})_{x_i&lt;x\\le x_i+10, t_i&lt;t\\le t_i+10}\\), 其中\\(x_i:=20+5i,t_i=1950+5i\\)。我们定义如下(原始)输入特征\\(W_{i,c}\\in\\mathbb{R}^{10\\times 10\\times 3}\\): \\[ \\begin{aligned} W_{i,c,\\cdot,\\cdot,1}:=&amp;(\\text{logit}(q_{x,t,c,males}))_{x_i&lt;x\\le x_i+10, t_i&lt;t\\le t_i+10}\\\\ W_{i,c,\\cdot,\\cdot,2}:=&amp;(\\text{logit}(q_{x,t,c,females}))_{x_i&lt;x\\le x_i+10, t_i&lt;t\\le t_i+10}\\\\ W_{i,c,\\cdot,\\cdot,3}:=&amp;W_{i,c,\\cdot,\\cdot,1}-W_{i,c,\\cdot,\\cdot,2} \\end{aligned} \\] Figure 1.2: Mortality Window 然后分别对三个通道进行正则化, 得到\\(\\boldsymbol{X}_{i,c}\\in[0,1]^{10\\times10\\times3}\\). 通过对所有国家进行如上处理, 可以得到大约\\(4000\\)张图像. 接下来, 我们定义每张图的“标签”. 首先, 对\\(r_{x,t,c,g}\\)进行MinMax正则化处理, 得到\\(\\bar{r}_{x,t,c,g}\\in[0,1].\\) 然后, 定义标签为异常强度 \\[Y_{i,c}:=\\underset{x_i&lt;x\\le x_i+10, t_i&lt;t\\le t_i+10}{\\max} \\left|\\frac{\\bar{r}_{x,t,c,males}+\\bar{r}_{x,t,c,females}}{2} \\right|\\in[0,1].\\] 我们的目标是基于死亡率在大小为\\(10\\times10\\)上的局部特征, 预测该范围内死亡率的异常强度. 在训练神经网络时, 选取均方误差损失函数\\[\\mathcal{L}(Y,\\hat{\\mu}(\\boldsymbol{X});\\mathcal{I}):=\\frac{1}{|\\mathcal{I}|}\\sum_{(i,c)\\in\\mathcal{I}}(Y_{i,c}-\\hat{\\mu}(\\boldsymbol{X}_{i,c}))^2.\\] 在评估模型时, 我们通过如下步骤定义二分类AOC指标: 定义伯努利随机变量 \\[ b_{i,c}:= \\begin{cases} 1, Y_{i,c}\\geq q_{0.95}(Y), \\\\ 0, \\text{otherwise}, \\end{cases} \\] 其中, \\(q_{0.95}(Y)\\)为所有因变量\\(Y_{i,c}\\)的0.95分位数, 即\\(b_{i,c}\\)为“非常异常”指示标量. 把神经网络的输出结果\\(\\hat{\\mu}(\\boldsymbol{X}_{i,c})\\)当作概率\\(\\Pr (b_{i,c}=1)\\)的预测. 画出该二分类问题的receiver operating characteristic curve (ROC), 并计算 area under the curve (AUC). 利用以上模型评估方法, 我们可以对国家按照“异常强度”的相似性进行分类, 具体步骤如下: 对每个国家\\(c\\)分别建立CNN模型, 并使用该模型对其他国家\\(c^*\\)的数据进行预测, 计算AUC \\(A_{c,c^*}\\). 并建立矩阵\\(A=(A_{c,c^*})_{c,c*\\in\\mathcal{C}}\\), 其中\\(\\mathcal{C}\\)为所有国家的集合. 对\\(A\\)进行列标准化, 并进行奇异值分解, 得到前两个主成分\\(P_{j,c}, j=1,2\\). 对主成分\\(P_{j,c}, j=1,2\\)进行聚类, 得到4个簇. 1.3.2 MNIST dataset 目标: 对手写\\(0-9\\)进行分类。 MNIST 全称为 Modified National Institute of Standards and Technology. 修改过后的MNIST数据集，它是一个由不同的人的手写体数字组成的图片数据集，包含了\\(7\\)万张关于手写数字\\(0,1,\\ldots,9\\)的图像，格式为\\(28×28\\)的灰度像素。 神经网络的输入为由灰度像素构成的\\(28\\times28\\)数组\\(\\boldsymbol{X}\\in[0,1]^{28\\times28}\\), 输出为在\\(\\{0,1,\\ldots,9\\}\\)上的离散分布\\((p_0,\\ldots,p_9)^T\\), 其中\\(\\sum_{j=0}^9p_j=1\\). 图像的标签为实际数字的one-hot编码\\(Y\\in\\{0,1\\}^{10}\\). 损失函数为交叉熵(cross-entropy) \\[\\mathcal{L}(Y,\\hat{p}(\\boldsymbol{X});\\mathcal{I}):=-\\sum_{i\\in\\mathcal{I}}\\sum_{j=0}^9Y_{i,j}\\log\\hat{p}_j(\\boldsymbol{X}_i).\\] "]]
