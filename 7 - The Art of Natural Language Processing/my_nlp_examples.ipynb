{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 该部分用简单的例子对nlp4class_exercise中部分函数做了说明，目的是为了对最终输入模型的数据形式有一个更加直观的了解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据清理：该cell对应nlp4class_exercise中的3.3\n",
    "# preprocessing by Raschka, Chpater 8 (see tutorial)\n",
    "# we remove all markups, substitute non-alphanumeric characters (including \n",
    "# underscore) with whitespaces, and remove the nose from emoticons\n",
    "# 删除所有的符号，把所有的非字母数字符号用空格替代，\n",
    "import re\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    #sub() 替换函数\n",
    "    #用’‘替换 <[^>]*> 这些字符\n",
    "    #即将 <[^>]*> 这些字符都删去\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    # 找到所有的符号\n",
    "    # ?: 匹配但不获取结果 要和其他的模式一起使用\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
    "            ' '.join(emoticons).replace('-', ''))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This movie is the only movie to feature a scene in which Michael Jackson wields a Tommy Gun. Plain and simple.<br /><br />This movie rocks because it is freaking' hilarious! It may be creepy to see Jacko w/ little kids, but this movie also stars.......................................... wait for it,.....................<br /><br />JOE PESCI!!!!!!!!!!!!!!!!!!!!!<br /><br />Think about it, Joe Pesci and Jacko with Tommy guns, throwing coins into jukeboxes from 20 feet away? Whats not to like? As stated before, THIS MOVIE ROCKS!!!!!!!!!!!! !!!!!!! !!!!!!!!!!! !!!!!!!! !!!! !!!!!!! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !!!!!!!!!!!!!! !!!!!!!!!! !!!!!!! ! !!!! !!!!!!!!!!!!!!!!!!!!!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie is the only movie to feature a scene in which Michael Jackson wields a Tommy Gun. Plain and simple.<br /><br />This movie rocks because it is freaking' hilarious! It may be creepy to see Jacko w/ little kids, but this movie also stars.......................................... wait for it,.....................<br /><br />JOE PESCI!!!!!!!!!!!!!!!!!!!!!<br /><br />Think about it, Joe Pesci and Jacko with Tommy guns, throwing coins into jukeboxes from 20 feet away? Whats not to like? As stated before, THIS MOVIE ROCKS!!!!!!!!!!!! !!!!!!! !!!!!!!!!!! !!!!!!!! !!!! !!!!!!! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! !!!!!!!!!!!!!! !!!!!!!!!! !!!!!!! ! !!!! !!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = preprocessor(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this movie is the only movie to feature a scene in which michael jackson wields a tommy gun plain and simple this movie rocks because it is freaking hilarious it may be creepy to see jacko w little kids but this movie also stars wait for it joe pesci think about it joe pesci and jacko with tommy guns throwing coins into jukeboxes from 20 feet away whats not to like as stated before this movie rocks \n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'movie', 'is', 'the', 'only', 'movie', 'to', 'feature', 'a', 'scene', 'in', 'which', 'michael', 'jackson', 'wields', 'a', 'tommy', 'gun', 'plain', 'and', 'simple', 'this', 'movie', 'rocks', 'because', 'it', 'is', 'freaking', 'hilarious', 'it', 'may', 'be', 'creepy', 'to', 'see', 'jacko', 'w', 'little', 'kids', 'but', 'this', 'movie', 'also', 'stars', 'wait', 'for', 'it', 'joe', 'pesci', 'think', 'about', 'it', 'joe', 'pesci', 'and', 'jacko', 'with', 'tommy', 'guns', 'throwing', 'coins', 'into', 'jukeboxes', 'from', '20', 'feet', 'away', 'whats', 'not', 'to', 'like', 'as', 'stated', 'before', 'this', 'movie', 'rocks']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 删除停止词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = list(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tokens = [word for word in tokens if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['about',\n",
       " 'to',\n",
       " 'into',\n",
       " 'is',\n",
       " 'in',\n",
       " 'and',\n",
       " 'not',\n",
       " 'the',\n",
       " 'for',\n",
       " 'before',\n",
       " 'this',\n",
       " 'a',\n",
       " 'with',\n",
       " 'only',\n",
       " 'because',\n",
       " 'which',\n",
       " 'but',\n",
       " 'it',\n",
       " 'be',\n",
       " 'from',\n",
       " 'as']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(tokens) - set(filtered_tokens))\n",
    "#查看去掉的停止词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_filtered = ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 词性标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def pos_tags(text_processed):\n",
    "    return \"-\".join( tag for (word, tag) in nltk.pos_tag(text_processed))\n",
    "\n",
    "pos_tag = pos_tags(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN-NN-NN-NN-NN-NN-NNS-JJ-NN-NN-JJ-NN-NNS-VBG-JJ-MD-VB-VB-JJ-JJ-JJ-NNS-NN-RB-VBZ-JJ-NN-NN-VBP-NN-NN-NN-NN-NNS-VBG-NNS-VBP-CD-NNS-RB-NNS-IN-VBN-NN-NNS\n"
     ]
    }
   ],
   "source": [
    "print(pos_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pos_tag是一个由“-”连接的字符串，它按顺序连接了经过预处理的文本中每个单词的词性数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_filtered_plus = 'I also love creepy coins'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_wm = tfidf.fit_transform([text_filtered, text_filtered_plus])\n",
    "tfidf_tokens = tfidf.get_feature_names()\n",
    "df_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray(),index = ['Doc1','Doc2'],columns = tfidf_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            20      also      away     coins    creepy   feature      feet\n",
      "Doc1  0.117429  0.083552  0.117429  0.083552  0.083552  0.117429  0.117429\n",
      "Doc2  0.000000  0.448321  0.000000  0.448321  0.448321  0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "print(df_tfidfvect.iloc[:,:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizer将文本转化为向量；\n",
    "向量的属性对应词典中的单词(n个)，属性值是每个单词的tfidf值；\n",
    "每个向量代表一个文本；\n",
    "n个文本构成n*p矩阵；\n",
    "bag of words模型最终输入的就是类似这样的矩阵；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_wm = tfidf.fit_transform([pos_tag])\n",
    "tfidf_tokens = tfidf.get_feature_names()\n",
    "df_tfidfvect = pd.DataFrame(data = tfidf_wm.toarray(),index = ['Doc1'],columns = tfidf_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            CD        IN        JJ        MD        NN       NNS        RB\n",
      "Doc1  0.048622  0.048622  0.340352  0.048622  0.826568  0.388973  0.097243\n"
     ]
    }
   ],
   "source": [
    "print(df_tfidfvect.iloc[:,:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把输入的文本改成文本对应的词性序列，得到的就是bag of words模型的输入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 词嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "emb = nlp(text_filtered).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.15745707  0.8379106  -1.0978016  -0.65186864 -0.16659321  0.23193046]\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "print(emb[:6])\n",
    "print(len(emb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据'en_core_web_sm'模型将文本转化为向量，向量的维数是由模型本身决定的。由这样的文本向量构成的矩阵就是word embeddings模型的最终输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
